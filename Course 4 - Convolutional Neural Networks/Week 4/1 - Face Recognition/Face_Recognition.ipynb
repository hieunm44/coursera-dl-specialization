{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition\n",
    "\n",
    "Welcome! In this assignment, you're going to build a face recognition system. Many of the ideas presented here are from [FaceNet](https://arxiv.org/pdf/1503.03832.pdf). In the lecture, you also encountered [DeepFace](https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf).\n",
    "\n",
    "Face recognition problems commonly fall into one of two categories: \n",
    "\n",
    "**Face Verification** \"Is this the claimed person?\" For example, at some airports, you can pass through customs by letting a system scan your passport and then verifying that you (the person carrying the passport) are the correct person. A mobile phone that unlocks using your face is also using face verification. This is a 1:1 matching problem.\n",
    "\n",
    "**Face Recognition** \"Who is this person?\" For example, the video lecture showed a [face recognition video](https://www.youtube.com/watch?v=wr4rx0Spihs) of Baidu employees entering the office without needing to otherwise identify themselves. This is a 1:K matching problem.\n",
    "\n",
    "FaceNet learns a neural network that encodes a face image into a vector of 128 numbers. By comparing two such vectors, you can then determine if two pictures are of the same person.\n",
    "\n",
    "By the end of this assignment, you'll be able to: \n",
    "\n",
    "* Differentiate between face recognition and face verification\n",
    "* Implement one-shot learning to solve a face recognition problem\n",
    "* Apply the triplet loss function to learn a network's parameters in the context of face recognition\n",
    "* Explain how to pose face recognition as a binary classification problem\n",
    "* Map face images into 128-dimensional encodings using a pretrained model\n",
    "* Perform face verification and face recognition with these encodings\n",
    "\n",
    "**Channels-last notation**\n",
    "\n",
    "For this assignment, you'll be using a pre-trained model which represents ConvNet activations using a \"channels last\" convention, as used during the lecture and in previous programming assignments.\n",
    "\n",
    "In other words, a batch of images will be of shape $(m, n_H, n_W, n_C)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "- [1 - Packages](#1)\n",
    "- [2 - Naive Face Verification](#2)\n",
    "- [3 - Encoding Face Images into a 128-Dimensional Vector](#3)\n",
    "    - [3.1 - Using a ConvNet to Compute Encodings](#3-1)\n",
    "    - [3.2 - The Triplet Loss](#3-2)\n",
    "        - [Exercise 1 - triplet_loss](#ex-1)\n",
    "- [4 - Loading the Pre-trained Model](#4)\n",
    "- [5 - Applying the Model](#5)\n",
    "    - [5.1 - Face Verification](#5-1)\n",
    "        - [Exercise 2 - verify](#ex-2)\n",
    "    - [5.2 - Face Recognition](#5-2)\n",
    "        - [Exercise 3 - who_is_it](#ex-3)\n",
    "- [6 - References](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Packages\n",
    "\n",
    "Go ahead and run the cell below to import the packages you'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image \n",
    "\n",
    "# %matplotlib inline\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Naive Face Verification\n",
    "\n",
    "In Face Verification, you're given two images and you have to determine if they are of the same person. The simplest way to do this is to compare the two images pixel-by-pixel. If the distance between the raw images is below a chosen threshold, it may be the same person!\n",
    "\n",
    "<img src=\"images/pixel_comparison.png\" style=\"width:380px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 1</b> </u></center></caption>\n",
    "\n",
    "Of course, this algorithm performs poorly, since the pixel values change dramatically due to variations in lighting, orientation of the person's face, minor changes in head position, and so on.\n",
    "\n",
    "You'll see that rather than using the raw image, you can learn an encoding, $f(img)$.\n",
    "\n",
    "By using an encoding for each image, an element-wise comparison produces a more accurate judgement as to whether two pictures are of the same person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Encoding Face Images into a 128-Dimensional Vector\n",
    "\n",
    "<a name='3-1'></a>\n",
    "### 3.1 - Using a ConvNet to Compute Encodings\n",
    "\n",
    "The FaceNet model takes a lot of data and a long time to train. So following the common practice in applied deep learning, you'll load weights that someone else has already trained. The network architecture follows the Inception model from [Szegedy *et al*..](https://arxiv.org/abs/1409.4842) An Inception network implementation has been provided for you, and you can find it in the file `inception_blocks_v2.py` to get a closer look at how it is implemented.  \n",
    "\n",
    "*Hot tip:* Go to \"File->Open...\" at the top of this notebook. This opens the file directory that contains the `.py` file).\n",
    "\n",
    "The key things to be aware of are:\n",
    "\n",
    "- This network uses 160x160 dimensional RGB images as its input. Specifically, a face image (or batch of $m$ face images) as a tensor of shape $(m, n_H, n_W, n_C) = (m, 160, 160, 3)$\n",
    "- The input images are originally of shape 96x96, thus, you need to scale them to 160x160. This is done in the `img_to_encoding()` function.\n",
    "- The output is a matrix of shape $(m, 128)$ that encodes each input face image into a 128-dimensional vector\n",
    "\n",
    "Run the cell below to create the model for face images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 04:49:05.860143: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-11 04:49:05.860478: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-11 04:49:05.860514: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-11 04:49:05.860539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-11 04:49:05.860563: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-01-11 04:49:05.860585: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-01-11 04:49:05.860607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-11 04:49:05.860629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-11 04:49:05.860650: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-11 04:49:05.860657: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-11 04:49:05.861053: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# MÃºst run with python <=3.7\n",
    "json_file = open('keras-facenet-h5/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights('keras-facenet-h5/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now summarize the input and output shapes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 160, 160, 3) dtype=float32 (created by layer 'input_1')>]\n",
      "[<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'Bottleneck_BatchNorm')>]\n"
     ]
    }
   ],
   "source": [
    "print(model.inputs)\n",
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_resnet_v1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv2d_1a_3x3 (Conv2D)         (None, 79, 79, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " Conv2d_1a_3x3_BatchNorm (Batch  (None, 79, 79, 32)  96          ['Conv2d_1a_3x3[0][0]']          \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv2d_1a_3x3_Activation (Acti  (None, 79, 79, 32)  0           ['Conv2d_1a_3x3_BatchNorm[0][0]']\n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " Conv2d_2a_3x3 (Conv2D)         (None, 77, 77, 32)   9216        ['Conv2d_1a_3x3_Activation[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " Conv2d_2a_3x3_BatchNorm (Batch  (None, 77, 77, 32)  96          ['Conv2d_2a_3x3[0][0]']          \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv2d_2a_3x3_Activation (Acti  (None, 77, 77, 32)  0           ['Conv2d_2a_3x3_BatchNorm[0][0]']\n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " Conv2d_2b_3x3 (Conv2D)         (None, 77, 77, 64)   18432       ['Conv2d_2a_3x3_Activation[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " Conv2d_2b_3x3_BatchNorm (Batch  (None, 77, 77, 64)  192         ['Conv2d_2b_3x3[0][0]']          \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv2d_2b_3x3_Activation (Acti  (None, 77, 77, 64)  0           ['Conv2d_2b_3x3_BatchNorm[0][0]']\n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " MaxPool_3a_3x3 (MaxPooling2D)  (None, 38, 38, 64)   0           ['Conv2d_2b_3x3_Activation[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " Conv2d_3b_1x1 (Conv2D)         (None, 38, 38, 80)   5120        ['MaxPool_3a_3x3[0][0]']         \n",
      "                                                                                                  \n",
      " Conv2d_3b_1x1_BatchNorm (Batch  (None, 38, 38, 80)  240         ['Conv2d_3b_1x1[0][0]']          \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv2d_3b_1x1_Activation (Acti  (None, 38, 38, 80)  0           ['Conv2d_3b_1x1_BatchNorm[0][0]']\n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " Conv2d_4a_3x3 (Conv2D)         (None, 36, 36, 192)  138240      ['Conv2d_3b_1x1_Activation[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " Conv2d_4a_3x3_BatchNorm (Batch  (None, 36, 36, 192)  576        ['Conv2d_4a_3x3[0][0]']          \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv2d_4a_3x3_Activation (Acti  (None, 36, 36, 192)  0          ['Conv2d_4a_3x3_BatchNorm[0][0]']\n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " Conv2d_4b_3x3 (Conv2D)         (None, 17, 17, 256)  442368      ['Conv2d_4a_3x3_Activation[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " Conv2d_4b_3x3_BatchNorm (Batch  (None, 17, 17, 256)  768        ['Conv2d_4b_3x3[0][0]']          \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv2d_4b_3x3_Activation (Acti  (None, 17, 17, 256)  0          ['Conv2d_4b_3x3_BatchNorm[0][0]']\n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " Block35_1_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  8192        ['Conv2d_4b_3x3_Activation[0][0]'\n",
      " x1 (Conv2D)                                                     ]                                \n",
      "                                                                                                  \n",
      " Block35_1_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  96          ['Block35_1_Branch_2_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_1_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  0           ['Block35_1_Branch_2_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_1_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  8192        ['Conv2d_4b_3x3_Activation[0][0]'\n",
      " x1 (Conv2D)                                                     ]                                \n",
      "                                                                                                  \n",
      " Block35_1_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  9216        ['Block35_1_Branch_2_Conv2d_0a_1x\n",
      " x3 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_1_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  96          ['Block35_1_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_1_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  96          ['Block35_1_Branch_2_Conv2d_0b_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_1_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  0           ['Block35_1_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_1_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  0           ['Block35_1_Branch_2_Conv2d_0b_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_1_Branch_0_Conv2d_1x1   (None, 17, 17, 32)  8192        ['Conv2d_4b_3x3_Activation[0][0]'\n",
      " (Conv2D)                                                        ]                                \n",
      "                                                                                                  \n",
      " Block35_1_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  9216        ['Block35_1_Branch_1_Conv2d_0a_1x\n",
      " x3 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_1_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  9216        ['Block35_1_Branch_2_Conv2d_0b_3x\n",
      " x3 (Conv2D)                                                     3_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_1_Branch_0_Conv2d_1x1_  (None, 17, 17, 32)  96          ['Block35_1_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block35_1_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  96          ['Block35_1_Branch_1_Conv2d_0b_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_1_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  96          ['Block35_1_Branch_2_Conv2d_0c_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_1_Branch_0_Conv2d_1x1_  (None, 17, 17, 32)  0           ['Block35_1_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block35_1_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  0           ['Block35_1_Branch_1_Conv2d_0b_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_1_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  0           ['Block35_1_Branch_2_Conv2d_0c_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_1_Concatenate (Concate  (None, 17, 17, 96)  0           ['Block35_1_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block35_1_Branch_1_Conv2d_0b_3x\n",
      "                                                                 3_Activation[0][0]',             \n",
      "                                                                  'Block35_1_Branch_2_Conv2d_0c_3x\n",
      "                                                                 3_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_1_Conv2d_1x1 (Conv2D)  (None, 17, 17, 256)  24832       ['Block35_1_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block35_1_ScaleSum (Lambda)    (None, 17, 17, 256)  0           ['Conv2d_4b_3x3_Activation[0][0]'\n",
      "                                                                 , 'Block35_1_Conv2d_1x1[0][0]']  \n",
      "                                                                                                  \n",
      " Block35_1_Activation (Activati  (None, 17, 17, 256)  0          ['Block35_1_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_2_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  8192        ['Block35_1_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block35_2_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  96          ['Block35_2_Branch_2_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_2_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  0           ['Block35_2_Branch_2_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_2_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  8192        ['Block35_1_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block35_2_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  9216        ['Block35_2_Branch_2_Conv2d_0a_1x\n",
      " x3 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_2_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  96          ['Block35_2_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_2_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  96          ['Block35_2_Branch_2_Conv2d_0b_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_2_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  0           ['Block35_2_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_2_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  0           ['Block35_2_Branch_2_Conv2d_0b_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_2_Branch_0_Conv2d_1x1   (None, 17, 17, 32)  8192        ['Block35_1_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block35_2_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  9216        ['Block35_2_Branch_1_Conv2d_0a_1x\n",
      " x3 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_2_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  9216        ['Block35_2_Branch_2_Conv2d_0b_3x\n",
      " x3 (Conv2D)                                                     3_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_2_Branch_0_Conv2d_1x1_  (None, 17, 17, 32)  96          ['Block35_2_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block35_2_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  96          ['Block35_2_Branch_1_Conv2d_0b_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_2_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  96          ['Block35_2_Branch_2_Conv2d_0c_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_2_Branch_0_Conv2d_1x1_  (None, 17, 17, 32)  0           ['Block35_2_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block35_2_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  0           ['Block35_2_Branch_1_Conv2d_0b_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_2_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  0           ['Block35_2_Branch_2_Conv2d_0c_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_2_Concatenate (Concate  (None, 17, 17, 96)  0           ['Block35_2_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block35_2_Branch_1_Conv2d_0b_3x\n",
      "                                                                 3_Activation[0][0]',             \n",
      "                                                                  'Block35_2_Branch_2_Conv2d_0c_3x\n",
      "                                                                 3_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_2_Conv2d_1x1 (Conv2D)  (None, 17, 17, 256)  24832       ['Block35_2_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block35_2_ScaleSum (Lambda)    (None, 17, 17, 256)  0           ['Block35_1_Activation[0][0]',   \n",
      "                                                                  'Block35_2_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block35_2_Activation (Activati  (None, 17, 17, 256)  0          ['Block35_2_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_3_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  8192        ['Block35_2_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block35_3_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  96          ['Block35_3_Branch_2_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_3_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  0           ['Block35_3_Branch_2_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_3_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  8192        ['Block35_2_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block35_3_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  9216        ['Block35_3_Branch_2_Conv2d_0a_1x\n",
      " x3 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_3_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  96          ['Block35_3_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_3_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  96          ['Block35_3_Branch_2_Conv2d_0b_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_3_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  0           ['Block35_3_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_3_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  0           ['Block35_3_Branch_2_Conv2d_0b_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_3_Branch_0_Conv2d_1x1   (None, 17, 17, 32)  8192        ['Block35_2_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block35_3_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  9216        ['Block35_3_Branch_1_Conv2d_0a_1x\n",
      " x3 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_3_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  9216        ['Block35_3_Branch_2_Conv2d_0b_3x\n",
      " x3 (Conv2D)                                                     3_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_3_Branch_0_Conv2d_1x1_  (None, 17, 17, 32)  96          ['Block35_3_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block35_3_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  96          ['Block35_3_Branch_1_Conv2d_0b_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_3_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  96          ['Block35_3_Branch_2_Conv2d_0c_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_3_Branch_0_Conv2d_1x1_  (None, 17, 17, 32)  0           ['Block35_3_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block35_3_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  0           ['Block35_3_Branch_1_Conv2d_0b_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_3_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  0           ['Block35_3_Branch_2_Conv2d_0c_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_3_Concatenate (Concate  (None, 17, 17, 96)  0           ['Block35_3_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block35_3_Branch_1_Conv2d_0b_3x\n",
      "                                                                 3_Activation[0][0]',             \n",
      "                                                                  'Block35_3_Branch_2_Conv2d_0c_3x\n",
      "                                                                 3_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_3_Conv2d_1x1 (Conv2D)  (None, 17, 17, 256)  24832       ['Block35_3_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block35_3_ScaleSum (Lambda)    (None, 17, 17, 256)  0           ['Block35_2_Activation[0][0]',   \n",
      "                                                                  'Block35_3_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block35_3_Activation (Activati  (None, 17, 17, 256)  0          ['Block35_3_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_4_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  8192        ['Block35_3_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block35_4_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  96          ['Block35_4_Branch_2_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_4_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  0           ['Block35_4_Branch_2_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_4_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  8192        ['Block35_3_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block35_4_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  9216        ['Block35_4_Branch_2_Conv2d_0a_1x\n",
      " x3 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_4_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  96          ['Block35_4_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_4_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  96          ['Block35_4_Branch_2_Conv2d_0b_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_4_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  0           ['Block35_4_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_4_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  0           ['Block35_4_Branch_2_Conv2d_0b_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_4_Branch_0_Conv2d_1x1   (None, 17, 17, 32)  8192        ['Block35_3_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block35_4_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  9216        ['Block35_4_Branch_1_Conv2d_0a_1x\n",
      " x3 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_4_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  9216        ['Block35_4_Branch_2_Conv2d_0b_3x\n",
      " x3 (Conv2D)                                                     3_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_4_Branch_0_Conv2d_1x1_  (None, 17, 17, 32)  96          ['Block35_4_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block35_4_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  96          ['Block35_4_Branch_1_Conv2d_0b_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_4_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  96          ['Block35_4_Branch_2_Conv2d_0c_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_4_Branch_0_Conv2d_1x1_  (None, 17, 17, 32)  0           ['Block35_4_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block35_4_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  0           ['Block35_4_Branch_1_Conv2d_0b_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_4_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  0           ['Block35_4_Branch_2_Conv2d_0c_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_4_Concatenate (Concate  (None, 17, 17, 96)  0           ['Block35_4_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block35_4_Branch_1_Conv2d_0b_3x\n",
      "                                                                 3_Activation[0][0]',             \n",
      "                                                                  'Block35_4_Branch_2_Conv2d_0c_3x\n",
      "                                                                 3_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_4_Conv2d_1x1 (Conv2D)  (None, 17, 17, 256)  24832       ['Block35_4_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block35_4_ScaleSum (Lambda)    (None, 17, 17, 256)  0           ['Block35_3_Activation[0][0]',   \n",
      "                                                                  'Block35_4_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block35_4_Activation (Activati  (None, 17, 17, 256)  0          ['Block35_4_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_5_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  8192        ['Block35_4_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block35_5_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  96          ['Block35_5_Branch_2_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_5_Branch_2_Conv2d_0a_1  (None, 17, 17, 32)  0           ['Block35_5_Branch_2_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_5_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  8192        ['Block35_4_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block35_5_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  9216        ['Block35_5_Branch_2_Conv2d_0a_1x\n",
      " x3 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_5_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  96          ['Block35_5_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_5_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  96          ['Block35_5_Branch_2_Conv2d_0b_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_5_Branch_1_Conv2d_0a_1  (None, 17, 17, 32)  0           ['Block35_5_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_5_Branch_2_Conv2d_0b_3  (None, 17, 17, 32)  0           ['Block35_5_Branch_2_Conv2d_0b_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_5_Branch_0_Conv2d_1x1   (None, 17, 17, 32)  8192        ['Block35_4_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block35_5_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  9216        ['Block35_5_Branch_1_Conv2d_0a_1x\n",
      " x3 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_5_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  9216        ['Block35_5_Branch_2_Conv2d_0b_3x\n",
      " x3 (Conv2D)                                                     3_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_5_Branch_0_Conv2d_1x1_  (None, 17, 17, 32)  96          ['Block35_5_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block35_5_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  96          ['Block35_5_Branch_1_Conv2d_0b_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_5_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  96          ['Block35_5_Branch_2_Conv2d_0c_3x\n",
      " x3_BatchNorm (BatchNormalizati                                  3[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block35_5_Branch_0_Conv2d_1x1_  (None, 17, 17, 32)  0           ['Block35_5_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block35_5_Branch_1_Conv2d_0b_3  (None, 17, 17, 32)  0           ['Block35_5_Branch_1_Conv2d_0b_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_5_Branch_2_Conv2d_0c_3  (None, 17, 17, 32)  0           ['Block35_5_Branch_2_Conv2d_0c_3x\n",
      " x3_Activation (Activation)                                      3_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block35_5_Concatenate (Concate  (None, 17, 17, 96)  0           ['Block35_5_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block35_5_Branch_1_Conv2d_0b_3x\n",
      "                                                                 3_Activation[0][0]',             \n",
      "                                                                  'Block35_5_Branch_2_Conv2d_0c_3x\n",
      "                                                                 3_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block35_5_Conv2d_1x1 (Conv2D)  (None, 17, 17, 256)  24832       ['Block35_5_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block35_5_ScaleSum (Lambda)    (None, 17, 17, 256)  0           ['Block35_4_Activation[0][0]',   \n",
      "                                                                  'Block35_5_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block35_5_Activation (Activati  (None, 17, 17, 256)  0          ['Block35_5_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_1_Conv2d_0a_1x  (None, 17, 17, 192)  49152      ['Block35_5_Activation[0][0]']   \n",
      " 1 (Conv2D)                                                                                       \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_1_Conv2d_0a_1x  (None, 17, 17, 192)  576        ['Mixed_6a_Branch_1_Conv2d_0a_1x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_1_Conv2d_0a_1x  (None, 17, 17, 192)  0          ['Mixed_6a_Branch_1_Conv2d_0a_1x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_1_Conv2d_0b_3x  (None, 17, 17, 192)  331776     ['Mixed_6a_Branch_1_Conv2d_0a_1x1\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_1_Conv2d_0b_3x  (None, 17, 17, 192)  576        ['Mixed_6a_Branch_1_Conv2d_0b_3x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_1_Conv2d_0b_3x  (None, 17, 17, 192)  0          ['Mixed_6a_Branch_1_Conv2d_0b_3x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_0_Conv2d_1a_3x  (None, 8, 8, 384)   884736      ['Block35_5_Activation[0][0]']   \n",
      " 3 (Conv2D)                                                                                       \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_1_Conv2d_1a_3x  (None, 8, 8, 256)   442368      ['Mixed_6a_Branch_1_Conv2d_0b_3x3\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_0_Conv2d_1a_3x  (None, 8, 8, 384)   1152        ['Mixed_6a_Branch_0_Conv2d_1a_3x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_1_Conv2d_1a_3x  (None, 8, 8, 256)   768         ['Mixed_6a_Branch_1_Conv2d_1a_3x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_0_Conv2d_1a_3x  (None, 8, 8, 384)   0           ['Mixed_6a_Branch_0_Conv2d_1a_3x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_1_Conv2d_1a_3x  (None, 8, 8, 256)   0           ['Mixed_6a_Branch_1_Conv2d_1a_3x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Mixed_6a_Branch_2_MaxPool_1a_3  (None, 8, 8, 256)   0           ['Block35_5_Activation[0][0]']   \n",
      " x3 (MaxPooling2D)                                                                                \n",
      "                                                                                                  \n",
      " Mixed_6a (Concatenate)         (None, 8, 8, 896)    0           ['Mixed_6a_Branch_0_Conv2d_1a_3x3\n",
      "                                                                 _Activation[0][0]',              \n",
      "                                                                  'Mixed_6a_Branch_1_Conv2d_1a_3x3\n",
      "                                                                 _Activation[0][0]',              \n",
      "                                                                  'Mixed_6a_Branch_2_MaxPool_1a_3x\n",
      "                                                                 3[0][0]']                        \n",
      "                                                                                                  \n",
      " Block17_1_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   114688      ['Mixed_6a[0][0]']               \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block17_1_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   384         ['Block17_1_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_1_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   0           ['Block17_1_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_1_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   114688      ['Block17_1_Branch_1_Conv2d_0a_1x\n",
      " x7 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_1_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   384         ['Block17_1_Branch_1_Conv2d_0b_1x\n",
      " x7_BatchNorm (BatchNormalizati                                  7[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_1_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   0           ['Block17_1_Branch_1_Conv2d_0b_1x\n",
      " x7_Activation (Activation)                                      7_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_1_Branch_0_Conv2d_1x1   (None, 8, 8, 128)   114688      ['Mixed_6a[0][0]']               \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block17_1_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   114688      ['Block17_1_Branch_1_Conv2d_0b_1x\n",
      " x1 (Conv2D)                                                     7_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_1_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   384         ['Block17_1_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block17_1_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   384         ['Block17_1_Branch_1_Conv2d_0c_7x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_1_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   0           ['Block17_1_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block17_1_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   0           ['Block17_1_Branch_1_Conv2d_0c_7x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_1_Concatenate (Concate  (None, 8, 8, 256)   0           ['Block17_1_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block17_1_Branch_1_Conv2d_0c_7x\n",
      "                                                                 1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_1_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      ['Block17_1_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block17_1_ScaleSum (Lambda)    (None, 8, 8, 896)    0           ['Mixed_6a[0][0]',               \n",
      "                                                                  'Block17_1_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block17_1_Activation (Activati  (None, 8, 8, 896)   0           ['Block17_1_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_2_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   114688      ['Block17_1_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block17_2_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   384         ['Block17_2_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_2_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   0           ['Block17_2_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_2_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   114688      ['Block17_2_Branch_1_Conv2d_0a_1x\n",
      " x7 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_2_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   384         ['Block17_2_Branch_1_Conv2d_0b_1x\n",
      " x7_BatchNorm (BatchNormalizati                                  7[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_2_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   0           ['Block17_2_Branch_1_Conv2d_0b_1x\n",
      " x7_Activation (Activation)                                      7_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_2_Branch_0_Conv2d_1x1   (None, 8, 8, 128)   114688      ['Block17_1_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block17_2_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   114688      ['Block17_2_Branch_1_Conv2d_0b_1x\n",
      " x1 (Conv2D)                                                     7_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_2_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   384         ['Block17_2_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block17_2_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   384         ['Block17_2_Branch_1_Conv2d_0c_7x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_2_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   0           ['Block17_2_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block17_2_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   0           ['Block17_2_Branch_1_Conv2d_0c_7x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_2_Concatenate (Concate  (None, 8, 8, 256)   0           ['Block17_2_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block17_2_Branch_1_Conv2d_0c_7x\n",
      "                                                                 1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_2_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      ['Block17_2_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block17_2_ScaleSum (Lambda)    (None, 8, 8, 896)    0           ['Block17_1_Activation[0][0]',   \n",
      "                                                                  'Block17_2_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block17_2_Activation (Activati  (None, 8, 8, 896)   0           ['Block17_2_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_3_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   114688      ['Block17_2_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block17_3_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   384         ['Block17_3_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_3_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   0           ['Block17_3_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_3_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   114688      ['Block17_3_Branch_1_Conv2d_0a_1x\n",
      " x7 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_3_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   384         ['Block17_3_Branch_1_Conv2d_0b_1x\n",
      " x7_BatchNorm (BatchNormalizati                                  7[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_3_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   0           ['Block17_3_Branch_1_Conv2d_0b_1x\n",
      " x7_Activation (Activation)                                      7_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_3_Branch_0_Conv2d_1x1   (None, 8, 8, 128)   114688      ['Block17_2_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block17_3_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   114688      ['Block17_3_Branch_1_Conv2d_0b_1x\n",
      " x1 (Conv2D)                                                     7_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_3_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   384         ['Block17_3_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block17_3_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   384         ['Block17_3_Branch_1_Conv2d_0c_7x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_3_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   0           ['Block17_3_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block17_3_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   0           ['Block17_3_Branch_1_Conv2d_0c_7x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_3_Concatenate (Concate  (None, 8, 8, 256)   0           ['Block17_3_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block17_3_Branch_1_Conv2d_0c_7x\n",
      "                                                                 1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_3_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      ['Block17_3_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block17_3_ScaleSum (Lambda)    (None, 8, 8, 896)    0           ['Block17_2_Activation[0][0]',   \n",
      "                                                                  'Block17_3_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block17_3_Activation (Activati  (None, 8, 8, 896)   0           ['Block17_3_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_4_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   114688      ['Block17_3_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block17_4_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   384         ['Block17_4_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_4_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   0           ['Block17_4_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_4_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   114688      ['Block17_4_Branch_1_Conv2d_0a_1x\n",
      " x7 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_4_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   384         ['Block17_4_Branch_1_Conv2d_0b_1x\n",
      " x7_BatchNorm (BatchNormalizati                                  7[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_4_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   0           ['Block17_4_Branch_1_Conv2d_0b_1x\n",
      " x7_Activation (Activation)                                      7_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_4_Branch_0_Conv2d_1x1   (None, 8, 8, 128)   114688      ['Block17_3_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block17_4_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   114688      ['Block17_4_Branch_1_Conv2d_0b_1x\n",
      " x1 (Conv2D)                                                     7_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_4_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   384         ['Block17_4_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block17_4_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   384         ['Block17_4_Branch_1_Conv2d_0c_7x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_4_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   0           ['Block17_4_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block17_4_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   0           ['Block17_4_Branch_1_Conv2d_0c_7x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_4_Concatenate (Concate  (None, 8, 8, 256)   0           ['Block17_4_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block17_4_Branch_1_Conv2d_0c_7x\n",
      "                                                                 1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_4_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      ['Block17_4_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block17_4_ScaleSum (Lambda)    (None, 8, 8, 896)    0           ['Block17_3_Activation[0][0]',   \n",
      "                                                                  'Block17_4_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block17_4_Activation (Activati  (None, 8, 8, 896)   0           ['Block17_4_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_5_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   114688      ['Block17_4_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block17_5_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   384         ['Block17_5_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_5_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   0           ['Block17_5_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_5_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   114688      ['Block17_5_Branch_1_Conv2d_0a_1x\n",
      " x7 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_5_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   384         ['Block17_5_Branch_1_Conv2d_0b_1x\n",
      " x7_BatchNorm (BatchNormalizati                                  7[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_5_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   0           ['Block17_5_Branch_1_Conv2d_0b_1x\n",
      " x7_Activation (Activation)                                      7_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_5_Branch_0_Conv2d_1x1   (None, 8, 8, 128)   114688      ['Block17_4_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block17_5_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   114688      ['Block17_5_Branch_1_Conv2d_0b_1x\n",
      " x1 (Conv2D)                                                     7_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_5_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   384         ['Block17_5_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block17_5_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   384         ['Block17_5_Branch_1_Conv2d_0c_7x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_5_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   0           ['Block17_5_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block17_5_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   0           ['Block17_5_Branch_1_Conv2d_0c_7x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_5_Concatenate (Concate  (None, 8, 8, 256)   0           ['Block17_5_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block17_5_Branch_1_Conv2d_0c_7x\n",
      "                                                                 1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_5_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      ['Block17_5_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block17_5_ScaleSum (Lambda)    (None, 8, 8, 896)    0           ['Block17_4_Activation[0][0]',   \n",
      "                                                                  'Block17_5_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block17_5_Activation (Activati  (None, 8, 8, 896)   0           ['Block17_5_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_6_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   114688      ['Block17_5_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block17_6_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   384         ['Block17_6_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_6_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   0           ['Block17_6_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_6_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   114688      ['Block17_6_Branch_1_Conv2d_0a_1x\n",
      " x7 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_6_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   384         ['Block17_6_Branch_1_Conv2d_0b_1x\n",
      " x7_BatchNorm (BatchNormalizati                                  7[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_6_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   0           ['Block17_6_Branch_1_Conv2d_0b_1x\n",
      " x7_Activation (Activation)                                      7_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_6_Branch_0_Conv2d_1x1   (None, 8, 8, 128)   114688      ['Block17_5_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block17_6_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   114688      ['Block17_6_Branch_1_Conv2d_0b_1x\n",
      " x1 (Conv2D)                                                     7_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_6_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   384         ['Block17_6_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block17_6_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   384         ['Block17_6_Branch_1_Conv2d_0c_7x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_6_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   0           ['Block17_6_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block17_6_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   0           ['Block17_6_Branch_1_Conv2d_0c_7x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_6_Concatenate (Concate  (None, 8, 8, 256)   0           ['Block17_6_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block17_6_Branch_1_Conv2d_0c_7x\n",
      "                                                                 1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_6_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      ['Block17_6_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block17_6_ScaleSum (Lambda)    (None, 8, 8, 896)    0           ['Block17_5_Activation[0][0]',   \n",
      "                                                                  'Block17_6_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block17_6_Activation (Activati  (None, 8, 8, 896)   0           ['Block17_6_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_7_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   114688      ['Block17_6_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block17_7_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   384         ['Block17_7_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_7_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   0           ['Block17_7_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_7_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   114688      ['Block17_7_Branch_1_Conv2d_0a_1x\n",
      " x7 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_7_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   384         ['Block17_7_Branch_1_Conv2d_0b_1x\n",
      " x7_BatchNorm (BatchNormalizati                                  7[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_7_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   0           ['Block17_7_Branch_1_Conv2d_0b_1x\n",
      " x7_Activation (Activation)                                      7_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_7_Branch_0_Conv2d_1x1   (None, 8, 8, 128)   114688      ['Block17_6_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block17_7_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   114688      ['Block17_7_Branch_1_Conv2d_0b_1x\n",
      " x1 (Conv2D)                                                     7_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_7_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   384         ['Block17_7_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block17_7_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   384         ['Block17_7_Branch_1_Conv2d_0c_7x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_7_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   0           ['Block17_7_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block17_7_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   0           ['Block17_7_Branch_1_Conv2d_0c_7x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_7_Concatenate (Concate  (None, 8, 8, 256)   0           ['Block17_7_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block17_7_Branch_1_Conv2d_0c_7x\n",
      "                                                                 1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_7_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      ['Block17_7_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block17_7_ScaleSum (Lambda)    (None, 8, 8, 896)    0           ['Block17_6_Activation[0][0]',   \n",
      "                                                                  'Block17_7_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block17_7_Activation (Activati  (None, 8, 8, 896)   0           ['Block17_7_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_8_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   114688      ['Block17_7_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block17_8_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   384         ['Block17_8_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_8_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   0           ['Block17_8_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_8_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   114688      ['Block17_8_Branch_1_Conv2d_0a_1x\n",
      " x7 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_8_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   384         ['Block17_8_Branch_1_Conv2d_0b_1x\n",
      " x7_BatchNorm (BatchNormalizati                                  7[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_8_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   0           ['Block17_8_Branch_1_Conv2d_0b_1x\n",
      " x7_Activation (Activation)                                      7_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_8_Branch_0_Conv2d_1x1   (None, 8, 8, 128)   114688      ['Block17_7_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block17_8_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   114688      ['Block17_8_Branch_1_Conv2d_0b_1x\n",
      " x1 (Conv2D)                                                     7_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_8_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   384         ['Block17_8_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block17_8_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   384         ['Block17_8_Branch_1_Conv2d_0c_7x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_8_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   0           ['Block17_8_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block17_8_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   0           ['Block17_8_Branch_1_Conv2d_0c_7x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_8_Concatenate (Concate  (None, 8, 8, 256)   0           ['Block17_8_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block17_8_Branch_1_Conv2d_0c_7x\n",
      "                                                                 1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_8_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      ['Block17_8_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block17_8_ScaleSum (Lambda)    (None, 8, 8, 896)    0           ['Block17_7_Activation[0][0]',   \n",
      "                                                                  'Block17_8_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block17_8_Activation (Activati  (None, 8, 8, 896)   0           ['Block17_8_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_9_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   114688      ['Block17_8_Activation[0][0]']   \n",
      " x1 (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " Block17_9_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   384         ['Block17_9_Branch_1_Conv2d_0a_1x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_9_Branch_1_Conv2d_0a_1  (None, 8, 8, 128)   0           ['Block17_9_Branch_1_Conv2d_0a_1x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_9_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   114688      ['Block17_9_Branch_1_Conv2d_0a_1x\n",
      " x7 (Conv2D)                                                     1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_9_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   384         ['Block17_9_Branch_1_Conv2d_0b_1x\n",
      " x7_BatchNorm (BatchNormalizati                                  7[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_9_Branch_1_Conv2d_0b_1  (None, 8, 8, 128)   0           ['Block17_9_Branch_1_Conv2d_0b_1x\n",
      " x7_Activation (Activation)                                      7_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_9_Branch_0_Conv2d_1x1   (None, 8, 8, 128)   114688      ['Block17_8_Activation[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " Block17_9_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   114688      ['Block17_9_Branch_1_Conv2d_0b_1x\n",
      " x1 (Conv2D)                                                     7_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_9_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   384         ['Block17_9_Branch_0_Conv2d_1x1[0\n",
      " BatchNorm (BatchNormalization)                                  ][0]']                           \n",
      "                                                                                                  \n",
      " Block17_9_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   384         ['Block17_9_Branch_1_Conv2d_0c_7x\n",
      " x1_BatchNorm (BatchNormalizati                                  1[0][0]']                        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_9_Branch_0_Conv2d_1x1_  (None, 8, 8, 128)   0           ['Block17_9_Branch_0_Conv2d_1x1_B\n",
      " Activation (Activation)                                         atchNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " Block17_9_Branch_1_Conv2d_0c_7  (None, 8, 8, 128)   0           ['Block17_9_Branch_1_Conv2d_0c_7x\n",
      " x1_Activation (Activation)                                      1_BatchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " Block17_9_Concatenate (Concate  (None, 8, 8, 256)   0           ['Block17_9_Branch_0_Conv2d_1x1_A\n",
      " nate)                                                           ctivation[0][0]',                \n",
      "                                                                  'Block17_9_Branch_1_Conv2d_0c_7x\n",
      "                                                                 1_Activation[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_9_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      ['Block17_9_Concatenate[0][0]']  \n",
      "                                                                                                  \n",
      " Block17_9_ScaleSum (Lambda)    (None, 8, 8, 896)    0           ['Block17_8_Activation[0][0]',   \n",
      "                                                                  'Block17_9_Conv2d_1x1[0][0]']   \n",
      "                                                                                                  \n",
      " Block17_9_Activation (Activati  (None, 8, 8, 896)   0           ['Block17_9_ScaleSum[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Block17_10_Branch_1_Conv2d_0a_  (None, 8, 8, 128)   114688      ['Block17_9_Activation[0][0]']   \n",
      " 1x1 (Conv2D)                                                                                     \n",
      "                                                                                                  \n",
      " Block17_10_Branch_1_Conv2d_0a_  (None, 8, 8, 128)   384         ['Block17_10_Branch_1_Conv2d_0a_1\n",
      " 1x1_BatchNorm (BatchNormalizat                                  x1[0][0]']                       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " Block17_10_Branch_1_Conv2d_0a_  (None, 8, 8, 128)   0           ['Block17_10_Branch_1_Conv2d_0a_1\n",
      " 1x1_Activation (Activation)                                     x1_BatchNorm[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_10_Branch_1_Conv2d_0b_  (None, 8, 8, 128)   114688      ['Block17_10_Branch_1_Conv2d_0a_1\n",
      " 1x7 (Conv2D)                                                    x1_Activation[0][0]']            \n",
      "                                                                                                  \n",
      " Block17_10_Branch_1_Conv2d_0b_  (None, 8, 8, 128)   384         ['Block17_10_Branch_1_Conv2d_0b_1\n",
      " 1x7_BatchNorm (BatchNormalizat                                  x7[0][0]']                       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " Block17_10_Branch_1_Conv2d_0b_  (None, 8, 8, 128)   0           ['Block17_10_Branch_1_Conv2d_0b_1\n",
      " 1x7_Activation (Activation)                                     x7_BatchNorm[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_10_Branch_0_Conv2d_1x1  (None, 8, 8, 128)   114688      ['Block17_9_Activation[0][0]']   \n",
      "  (Conv2D)                                                                                        \n",
      "                                                                                                  \n",
      " Block17_10_Branch_1_Conv2d_0c_  (None, 8, 8, 128)   114688      ['Block17_10_Branch_1_Conv2d_0b_1\n",
      " 7x1 (Conv2D)                                                    x7_Activation[0][0]']            \n",
      "                                                                                                  \n",
      " Block17_10_Branch_0_Conv2d_1x1  (None, 8, 8, 128)   384         ['Block17_10_Branch_0_Conv2d_1x1[\n",
      " _BatchNorm (BatchNormalization                                  0][0]']                          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Block17_10_Branch_1_Conv2d_0c_  (None, 8, 8, 128)   384         ['Block17_10_Branch_1_Conv2d_0c_7\n",
      " 7x1_BatchNorm (BatchNormalizat                                  x1[0][0]']                       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " Block17_10_Branch_0_Conv2d_1x1  (None, 8, 8, 128)   0           ['Block17_10_Branch_0_Conv2d_1x1_\n",
      " _Activation (Activation)                                        BatchNorm[0][0]']                \n",
      "                                                                                                  \n",
      " Block17_10_Branch_1_Conv2d_0c_  (None, 8, 8, 128)   0           ['Block17_10_Branch_1_Conv2d_0c_7\n",
      " 7x1_Activation (Activation)                                     x1_BatchNorm[0][0]']             \n",
      "                                                                                                  \n",
      " Block17_10_Concatenate (Concat  (None, 8, 8, 256)   0           ['Block17_10_Branch_0_Conv2d_1x1_\n",
      " enate)                                                          Activation[0][0]',               \n",
      "                                                                  'Block17_10_Branch_1_Conv2d_0c_7\n",
      "                                                                 x1_Activation[0][0]']            \n",
      "                                                                                                  \n",
      " Block17_10_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)   230272      ['Block17_10_Concatenate[0][0]'] \n",
      "                                                                                                  \n",
      " Block17_10_ScaleSum (Lambda)   (None, 8, 8, 896)    0           ['Block17_9_Activation[0][0]',   \n",
      "                                                                  'Block17_10_Conv2d_1x1[0][0]']  \n",
      "                                                                                                  \n",
      " Block17_10_Activation (Activat  (None, 8, 8, 896)   0           ['Block17_10_ScaleSum[0][0]']    \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_2_Conv2d_0a_1x  (None, 8, 8, 256)   229376      ['Block17_10_Activation[0][0]']  \n",
      " 1 (Conv2D)                                                                                       \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_2_Conv2d_0a_1x  (None, 8, 8, 256)   768         ['Mixed_7a_Branch_2_Conv2d_0a_1x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_2_Conv2d_0a_1x  (None, 8, 8, 256)   0           ['Mixed_7a_Branch_2_Conv2d_0a_1x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_0_Conv2d_0a_1x  (None, 8, 8, 256)   229376      ['Block17_10_Activation[0][0]']  \n",
      " 1 (Conv2D)                                                                                       \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_1_Conv2d_0a_1x  (None, 8, 8, 256)   229376      ['Block17_10_Activation[0][0]']  \n",
      " 1 (Conv2D)                                                                                       \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_2_Conv2d_0b_3x  (None, 8, 8, 256)   589824      ['Mixed_7a_Branch_2_Conv2d_0a_1x1\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_0_Conv2d_0a_1x  (None, 8, 8, 256)   768         ['Mixed_7a_Branch_0_Conv2d_0a_1x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_1_Conv2d_0a_1x  (None, 8, 8, 256)   768         ['Mixed_7a_Branch_1_Conv2d_0a_1x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_2_Conv2d_0b_3x  (None, 8, 8, 256)   768         ['Mixed_7a_Branch_2_Conv2d_0b_3x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_0_Conv2d_0a_1x  (None, 8, 8, 256)   0           ['Mixed_7a_Branch_0_Conv2d_0a_1x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_1_Conv2d_0a_1x  (None, 8, 8, 256)   0           ['Mixed_7a_Branch_1_Conv2d_0a_1x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_2_Conv2d_0b_3x  (None, 8, 8, 256)   0           ['Mixed_7a_Branch_2_Conv2d_0b_3x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_0_Conv2d_1a_3x  (None, 3, 3, 384)   884736      ['Mixed_7a_Branch_0_Conv2d_0a_1x1\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_1_Conv2d_1a_3x  (None, 3, 3, 256)   589824      ['Mixed_7a_Branch_1_Conv2d_0a_1x1\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_2_Conv2d_1a_3x  (None, 3, 3, 256)   589824      ['Mixed_7a_Branch_2_Conv2d_0b_3x3\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_0_Conv2d_1a_3x  (None, 3, 3, 384)   1152        ['Mixed_7a_Branch_0_Conv2d_1a_3x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_1_Conv2d_1a_3x  (None, 3, 3, 256)   768         ['Mixed_7a_Branch_1_Conv2d_1a_3x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_2_Conv2d_1a_3x  (None, 3, 3, 256)   768         ['Mixed_7a_Branch_2_Conv2d_1a_3x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_0_Conv2d_1a_3x  (None, 3, 3, 384)   0           ['Mixed_7a_Branch_0_Conv2d_1a_3x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_1_Conv2d_1a_3x  (None, 3, 3, 256)   0           ['Mixed_7a_Branch_1_Conv2d_1a_3x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_2_Conv2d_1a_3x  (None, 3, 3, 256)   0           ['Mixed_7a_Branch_2_Conv2d_1a_3x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Mixed_7a_Branch_3_MaxPool_1a_3  (None, 3, 3, 896)   0           ['Block17_10_Activation[0][0]']  \n",
      " x3 (MaxPooling2D)                                                                                \n",
      "                                                                                                  \n",
      " Mixed_7a (Concatenate)         (None, 3, 3, 1792)   0           ['Mixed_7a_Branch_0_Conv2d_1a_3x3\n",
      "                                                                 _Activation[0][0]',              \n",
      "                                                                  'Mixed_7a_Branch_1_Conv2d_1a_3x3\n",
      "                                                                 _Activation[0][0]',              \n",
      "                                                                  'Mixed_7a_Branch_2_Conv2d_1a_3x3\n",
      "                                                                 _Activation[0][0]',              \n",
      "                                                                  'Mixed_7a_Branch_3_MaxPool_1a_3x\n",
      "                                                                 3[0][0]']                        \n",
      "                                                                                                  \n",
      " Block8_1_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   344064      ['Mixed_7a[0][0]']               \n",
      " 1 (Conv2D)                                                                                       \n",
      "                                                                                                  \n",
      " Block8_1_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   576         ['Block8_1_Branch_1_Conv2d_0a_1x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_1_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   0           ['Block8_1_Branch_1_Conv2d_0a_1x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_1_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   110592      ['Block8_1_Branch_1_Conv2d_0a_1x1\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_1_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   576         ['Block8_1_Branch_1_Conv2d_0b_1x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_1_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   0           ['Block8_1_Branch_1_Conv2d_0b_1x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_1_Branch_0_Conv2d_1x1 (  (None, 3, 3, 192)   344064      ['Mixed_7a[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " Block8_1_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   110592      ['Block8_1_Branch_1_Conv2d_0b_1x3\n",
      " 1 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_1_Branch_0_Conv2d_1x1_B  (None, 3, 3, 192)   576         ['Block8_1_Branch_0_Conv2d_1x1[0]\n",
      " atchNorm (BatchNormalization)                                   [0]']                            \n",
      "                                                                                                  \n",
      " Block8_1_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   576         ['Block8_1_Branch_1_Conv2d_0c_3x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_1_Branch_0_Conv2d_1x1_A  (None, 3, 3, 192)   0           ['Block8_1_Branch_0_Conv2d_1x1_Ba\n",
      " ctivation (Activation)                                          tchNorm[0][0]']                  \n",
      "                                                                                                  \n",
      " Block8_1_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   0           ['Block8_1_Branch_1_Conv2d_0c_3x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_1_Concatenate (Concaten  (None, 3, 3, 384)   0           ['Block8_1_Branch_0_Conv2d_1x1_Ac\n",
      " ate)                                                            tivation[0][0]',                 \n",
      "                                                                  'Block8_1_Branch_1_Conv2d_0c_3x1\n",
      "                                                                 _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_1_Conv2d_1x1 (Conv2D)   (None, 3, 3, 1792)   689920      ['Block8_1_Concatenate[0][0]']   \n",
      "                                                                                                  \n",
      " Block8_1_ScaleSum (Lambda)     (None, 3, 3, 1792)   0           ['Mixed_7a[0][0]',               \n",
      "                                                                  'Block8_1_Conv2d_1x1[0][0]']    \n",
      "                                                                                                  \n",
      " Block8_1_Activation (Activatio  (None, 3, 3, 1792)  0           ['Block8_1_ScaleSum[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_2_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   344064      ['Block8_1_Activation[0][0]']    \n",
      " 1 (Conv2D)                                                                                       \n",
      "                                                                                                  \n",
      " Block8_2_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   576         ['Block8_2_Branch_1_Conv2d_0a_1x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_2_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   0           ['Block8_2_Branch_1_Conv2d_0a_1x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_2_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   110592      ['Block8_2_Branch_1_Conv2d_0a_1x1\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_2_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   576         ['Block8_2_Branch_1_Conv2d_0b_1x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_2_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   0           ['Block8_2_Branch_1_Conv2d_0b_1x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_2_Branch_0_Conv2d_1x1 (  (None, 3, 3, 192)   344064      ['Block8_1_Activation[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " Block8_2_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   110592      ['Block8_2_Branch_1_Conv2d_0b_1x3\n",
      " 1 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_2_Branch_0_Conv2d_1x1_B  (None, 3, 3, 192)   576         ['Block8_2_Branch_0_Conv2d_1x1[0]\n",
      " atchNorm (BatchNormalization)                                   [0]']                            \n",
      "                                                                                                  \n",
      " Block8_2_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   576         ['Block8_2_Branch_1_Conv2d_0c_3x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_2_Branch_0_Conv2d_1x1_A  (None, 3, 3, 192)   0           ['Block8_2_Branch_0_Conv2d_1x1_Ba\n",
      " ctivation (Activation)                                          tchNorm[0][0]']                  \n",
      "                                                                                                  \n",
      " Block8_2_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   0           ['Block8_2_Branch_1_Conv2d_0c_3x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_2_Concatenate (Concaten  (None, 3, 3, 384)   0           ['Block8_2_Branch_0_Conv2d_1x1_Ac\n",
      " ate)                                                            tivation[0][0]',                 \n",
      "                                                                  'Block8_2_Branch_1_Conv2d_0c_3x1\n",
      "                                                                 _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_2_Conv2d_1x1 (Conv2D)   (None, 3, 3, 1792)   689920      ['Block8_2_Concatenate[0][0]']   \n",
      "                                                                                                  \n",
      " Block8_2_ScaleSum (Lambda)     (None, 3, 3, 1792)   0           ['Block8_1_Activation[0][0]',    \n",
      "                                                                  'Block8_2_Conv2d_1x1[0][0]']    \n",
      "                                                                                                  \n",
      " Block8_2_Activation (Activatio  (None, 3, 3, 1792)  0           ['Block8_2_ScaleSum[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_3_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   344064      ['Block8_2_Activation[0][0]']    \n",
      " 1 (Conv2D)                                                                                       \n",
      "                                                                                                  \n",
      " Block8_3_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   576         ['Block8_3_Branch_1_Conv2d_0a_1x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_3_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   0           ['Block8_3_Branch_1_Conv2d_0a_1x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_3_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   110592      ['Block8_3_Branch_1_Conv2d_0a_1x1\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_3_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   576         ['Block8_3_Branch_1_Conv2d_0b_1x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_3_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   0           ['Block8_3_Branch_1_Conv2d_0b_1x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_3_Branch_0_Conv2d_1x1 (  (None, 3, 3, 192)   344064      ['Block8_2_Activation[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " Block8_3_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   110592      ['Block8_3_Branch_1_Conv2d_0b_1x3\n",
      " 1 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_3_Branch_0_Conv2d_1x1_B  (None, 3, 3, 192)   576         ['Block8_3_Branch_0_Conv2d_1x1[0]\n",
      " atchNorm (BatchNormalization)                                   [0]']                            \n",
      "                                                                                                  \n",
      " Block8_3_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   576         ['Block8_3_Branch_1_Conv2d_0c_3x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_3_Branch_0_Conv2d_1x1_A  (None, 3, 3, 192)   0           ['Block8_3_Branch_0_Conv2d_1x1_Ba\n",
      " ctivation (Activation)                                          tchNorm[0][0]']                  \n",
      "                                                                                                  \n",
      " Block8_3_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   0           ['Block8_3_Branch_1_Conv2d_0c_3x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_3_Concatenate (Concaten  (None, 3, 3, 384)   0           ['Block8_3_Branch_0_Conv2d_1x1_Ac\n",
      " ate)                                                            tivation[0][0]',                 \n",
      "                                                                  'Block8_3_Branch_1_Conv2d_0c_3x1\n",
      "                                                                 _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_3_Conv2d_1x1 (Conv2D)   (None, 3, 3, 1792)   689920      ['Block8_3_Concatenate[0][0]']   \n",
      "                                                                                                  \n",
      " Block8_3_ScaleSum (Lambda)     (None, 3, 3, 1792)   0           ['Block8_2_Activation[0][0]',    \n",
      "                                                                  'Block8_3_Conv2d_1x1[0][0]']    \n",
      "                                                                                                  \n",
      " Block8_3_Activation (Activatio  (None, 3, 3, 1792)  0           ['Block8_3_ScaleSum[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_4_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   344064      ['Block8_3_Activation[0][0]']    \n",
      " 1 (Conv2D)                                                                                       \n",
      "                                                                                                  \n",
      " Block8_4_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   576         ['Block8_4_Branch_1_Conv2d_0a_1x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_4_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   0           ['Block8_4_Branch_1_Conv2d_0a_1x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_4_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   110592      ['Block8_4_Branch_1_Conv2d_0a_1x1\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_4_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   576         ['Block8_4_Branch_1_Conv2d_0b_1x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_4_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   0           ['Block8_4_Branch_1_Conv2d_0b_1x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_4_Branch_0_Conv2d_1x1 (  (None, 3, 3, 192)   344064      ['Block8_3_Activation[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " Block8_4_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   110592      ['Block8_4_Branch_1_Conv2d_0b_1x3\n",
      " 1 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_4_Branch_0_Conv2d_1x1_B  (None, 3, 3, 192)   576         ['Block8_4_Branch_0_Conv2d_1x1[0]\n",
      " atchNorm (BatchNormalization)                                   [0]']                            \n",
      "                                                                                                  \n",
      " Block8_4_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   576         ['Block8_4_Branch_1_Conv2d_0c_3x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_4_Branch_0_Conv2d_1x1_A  (None, 3, 3, 192)   0           ['Block8_4_Branch_0_Conv2d_1x1_Ba\n",
      " ctivation (Activation)                                          tchNorm[0][0]']                  \n",
      "                                                                                                  \n",
      " Block8_4_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   0           ['Block8_4_Branch_1_Conv2d_0c_3x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_4_Concatenate (Concaten  (None, 3, 3, 384)   0           ['Block8_4_Branch_0_Conv2d_1x1_Ac\n",
      " ate)                                                            tivation[0][0]',                 \n",
      "                                                                  'Block8_4_Branch_1_Conv2d_0c_3x1\n",
      "                                                                 _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_4_Conv2d_1x1 (Conv2D)   (None, 3, 3, 1792)   689920      ['Block8_4_Concatenate[0][0]']   \n",
      "                                                                                                  \n",
      " Block8_4_ScaleSum (Lambda)     (None, 3, 3, 1792)   0           ['Block8_3_Activation[0][0]',    \n",
      "                                                                  'Block8_4_Conv2d_1x1[0][0]']    \n",
      "                                                                                                  \n",
      " Block8_4_Activation (Activatio  (None, 3, 3, 1792)  0           ['Block8_4_ScaleSum[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_5_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   344064      ['Block8_4_Activation[0][0]']    \n",
      " 1 (Conv2D)                                                                                       \n",
      "                                                                                                  \n",
      " Block8_5_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   576         ['Block8_5_Branch_1_Conv2d_0a_1x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_5_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   0           ['Block8_5_Branch_1_Conv2d_0a_1x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_5_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   110592      ['Block8_5_Branch_1_Conv2d_0a_1x1\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_5_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   576         ['Block8_5_Branch_1_Conv2d_0b_1x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_5_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   0           ['Block8_5_Branch_1_Conv2d_0b_1x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_5_Branch_0_Conv2d_1x1 (  (None, 3, 3, 192)   344064      ['Block8_4_Activation[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " Block8_5_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   110592      ['Block8_5_Branch_1_Conv2d_0b_1x3\n",
      " 1 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_5_Branch_0_Conv2d_1x1_B  (None, 3, 3, 192)   576         ['Block8_5_Branch_0_Conv2d_1x1[0]\n",
      " atchNorm (BatchNormalization)                                   [0]']                            \n",
      "                                                                                                  \n",
      " Block8_5_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   576         ['Block8_5_Branch_1_Conv2d_0c_3x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_5_Branch_0_Conv2d_1x1_A  (None, 3, 3, 192)   0           ['Block8_5_Branch_0_Conv2d_1x1_Ba\n",
      " ctivation (Activation)                                          tchNorm[0][0]']                  \n",
      "                                                                                                  \n",
      " Block8_5_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   0           ['Block8_5_Branch_1_Conv2d_0c_3x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_5_Concatenate (Concaten  (None, 3, 3, 384)   0           ['Block8_5_Branch_0_Conv2d_1x1_Ac\n",
      " ate)                                                            tivation[0][0]',                 \n",
      "                                                                  'Block8_5_Branch_1_Conv2d_0c_3x1\n",
      "                                                                 _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_5_Conv2d_1x1 (Conv2D)   (None, 3, 3, 1792)   689920      ['Block8_5_Concatenate[0][0]']   \n",
      "                                                                                                  \n",
      " Block8_5_ScaleSum (Lambda)     (None, 3, 3, 1792)   0           ['Block8_4_Activation[0][0]',    \n",
      "                                                                  'Block8_5_Conv2d_1x1[0][0]']    \n",
      "                                                                                                  \n",
      " Block8_5_Activation (Activatio  (None, 3, 3, 1792)  0           ['Block8_5_ScaleSum[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_6_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   344064      ['Block8_5_Activation[0][0]']    \n",
      " 1 (Conv2D)                                                                                       \n",
      "                                                                                                  \n",
      " Block8_6_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   576         ['Block8_6_Branch_1_Conv2d_0a_1x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_6_Branch_1_Conv2d_0a_1x  (None, 3, 3, 192)   0           ['Block8_6_Branch_1_Conv2d_0a_1x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_6_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   110592      ['Block8_6_Branch_1_Conv2d_0a_1x1\n",
      " 3 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_6_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   576         ['Block8_6_Branch_1_Conv2d_0b_1x3\n",
      " 3_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_6_Branch_1_Conv2d_0b_1x  (None, 3, 3, 192)   0           ['Block8_6_Branch_1_Conv2d_0b_1x3\n",
      " 3_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_6_Branch_0_Conv2d_1x1 (  (None, 3, 3, 192)   344064      ['Block8_5_Activation[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " Block8_6_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   110592      ['Block8_6_Branch_1_Conv2d_0b_1x3\n",
      " 1 (Conv2D)                                                      _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_6_Branch_0_Conv2d_1x1_B  (None, 3, 3, 192)   576         ['Block8_6_Branch_0_Conv2d_1x1[0]\n",
      " atchNorm (BatchNormalization)                                   [0]']                            \n",
      "                                                                                                  \n",
      " Block8_6_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   576         ['Block8_6_Branch_1_Conv2d_0c_3x1\n",
      " 1_BatchNorm (BatchNormalizatio                                  [0][0]']                         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Block8_6_Branch_0_Conv2d_1x1_A  (None, 3, 3, 192)   0           ['Block8_6_Branch_0_Conv2d_1x1_Ba\n",
      " ctivation (Activation)                                          tchNorm[0][0]']                  \n",
      "                                                                                                  \n",
      " Block8_6_Branch_1_Conv2d_0c_3x  (None, 3, 3, 192)   0           ['Block8_6_Branch_1_Conv2d_0c_3x1\n",
      " 1_Activation (Activation)                                       _BatchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " Block8_6_Concatenate (Concaten  (None, 3, 3, 384)   0           ['Block8_6_Branch_0_Conv2d_1x1_Ac\n",
      " ate)                                                            tivation[0][0]',                 \n",
      "                                                                  'Block8_6_Branch_1_Conv2d_0c_3x1\n",
      "                                                                 _Activation[0][0]']              \n",
      "                                                                                                  \n",
      " Block8_6_Conv2d_1x1 (Conv2D)   (None, 3, 3, 1792)   689920      ['Block8_6_Concatenate[0][0]']   \n",
      "                                                                                                  \n",
      " Block8_6_ScaleSum (Lambda)     (None, 3, 3, 1792)   0           ['Block8_5_Activation[0][0]',    \n",
      "                                                                  'Block8_6_Conv2d_1x1[0][0]']    \n",
      "                                                                                                  \n",
      " AvgPool (GlobalAveragePooling2  (None, 1792)        0           ['Block8_6_ScaleSum[0][0]']      \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " Dropout (Dropout)              (None, 1792)         0           ['AvgPool[0][0]']                \n",
      "                                                                                                  \n",
      " Bottleneck (Dense)             (None, 128)          229376      ['Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Bottleneck_BatchNorm (BatchNor  (None, 128)         384         ['Bottleneck[0][0]']             \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,808,144\n",
      "Trainable params: 22,779,312\n",
      "Non-trainable params: 28,832\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using a 128-neuron fully connected layer as its last layer, the model ensures that the output is an encoding vector of size 128. You then use the encodings to compare two face images as follows:\n",
    "\n",
    "<img src=\"images/distance_kiank.png\" style=\"width:680px;height:250px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 2:</b> <br> </u> <font color='purple'>By computing the distance between two encodings and thresholding, you can determine if the two pictures represent the same person</center></caption>\n",
    "\n",
    "So, an encoding is a good one if:\n",
    "\n",
    "- The encodings of two images of the same person are quite similar to each other.\n",
    "- The encodings of two images of different persons are very different.\n",
    "\n",
    "The triplet loss function formalizes this, and tries to \"push\" the encodings of two images of the same person (Anchor and Positive) closer together, while \"pulling\" the encodings of two images of different persons (Anchor, Negative) further apart.\n",
    "    \n",
    "<img src=\"images/triplet_comparison.png\" style=\"width:280px;height:150px;\"><br>\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 3: </b> <br> </u> <font color='purple'> In the next section,  you'll call the pictures from left to right: Anchor (A), Positive (P), Negative (N)</center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 - The Triplet Loss\n",
    "\n",
    "**Important Note**: Since you're using a pretrained model, you won't actually need to implement the triplet loss function in this assignment. *However*, the triplet loss is the main ingredient of the face recognition algorithm, and you'll need to know how to use it for training your own FaceNet model, as well as other types of image similarity problems. Therefore, you'll implement it below, for fun and edification. :) \n",
    "\n",
    "For an image $x$, its encoding is denoted as $f(x)$, where $f$ is the function computed by the neural network.\n",
    "\n",
    "<img src=\"images/f_x.png\" style=\"width:380px;height:150px;\">\n",
    "\n",
    "Training will use triplets of images $(A, P, N)$:\n",
    "\n",
    "- A is an \"Anchor\" image--a picture of a person.\n",
    "- P is a \"Positive\" image--a picture of the same person as the Anchor image.\n",
    "- N is a \"Negative\" image--a picture of a different person than the Anchor image.\n",
    "\n",
    "These triplets are picked from the training dataset. $(A^{(i)}, P^{(i)}, N^{(i)})$ is used here to denote the $i$-th training example.\n",
    "\n",
    "You'd like to make sure that an image $A^{(i)}$ of an individual is closer to the Positive $P^{(i)}$ than to the Negative image $N^{(i)}$) by at least a margin $\\alpha$:\n",
    "\n",
    "$$\n",
    "|| f\\left(A^{(i)}\\right)-f\\left(P^{(i)}\\right)||_{2}^{2}+\\alpha<|| f\\left(A^{(i)}\\right)-f\\left(N^{(i)}\\right)||_{2}^{2}\n",
    "$$\n",
    "\n",
    "\n",
    "You would thus like to minimize the following \"triplet cost\":\n",
    "\n",
    "$$\\mathcal{J} = \\sum^{m}_{i=1} \\large[ \\small \\underbrace{\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2}_\\text{(1)} - \\underbrace{\\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2}_\\text{(2)} + \\alpha \\large ] \\small_+ \\tag{3}$$\n",
    "Here, the notation \"$[z]_+$\" is used to denote $max(z,0)$.\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "- The term (1) is the squared distance between the anchor \"A\" and the positive \"P\" for a given triplet; you want this to be small.\n",
    "- The term (2) is the squared distance between the anchor \"A\" and the negative \"N\" for a given triplet, you want this to be relatively large. It has a minus sign preceding it because minimizing the negative of the term is the same as maximizing that term.\n",
    "- $\\alpha$ is called the margin. It's a hyperparameter that you pick manually. You'll use $\\alpha = 0.2$.\n",
    "\n",
    "Most implementations also rescale the encoding vectors to haven L2 norm equal to one (i.e., $\\mid \\mid f(img)\\mid \\mid_2$=1); you won't have to worry about that in this assignment.\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - triplet_loss\n",
    "\n",
    "Implement the triplet loss as defined by formula (3). These are the 4 steps:\n",
    "\n",
    "1. Compute the distance between the encodings of \"anchor\" and \"positive\": $\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2$\n",
    "2. Compute the distance between the encodings of \"anchor\" and \"negative\": $\\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2$\n",
    "3. Compute the formula per training example: $ \\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2 - \\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2 + \\alpha$\n",
    "4. Compute the full formula by taking the max with zero and summing over the training examples:$$\\mathcal{J} = \\sum^{m}_{i=1} \\large[ \\small \\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2 - \\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2+ \\alpha \\large ] \\small_+ \\tag{3}$$\n",
    "\n",
    "*Hints*:\n",
    "\n",
    "- Useful functions: `tf.reduce_sum()`, `tf.square()`, `tf.subtract()`, `tf.add()`, `tf.maximum()`.\n",
    "\n",
    "- For steps 1 and 2, sum over the entries of $\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2$ and $\\mid \\mid     f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2$.\n",
    "\n",
    "- For step 4, you will sum over the training examples.\n",
    "\n",
    "*Additional Hints*:\n",
    "\n",
    "- Recall that the square of the L2 norm is the sum of the squared differences: $||x - y||_{2}^{2} = \\sum_{i=1}^{N}(x_{i} - y_{i})^{2}$\n",
    "\n",
    "- Note that the anchor, positive and negative encodings are of shape (*m*,128), where *m* is the number of training examples and 128 is the number of elements used to encode a single example.\n",
    "\n",
    "- For steps 1 and 2, maintain the number of *m* training examples and sum along the 128 values of each encoding. `tf.reduce_sum` has an axis parameter. This chooses along which axis the sums are applied.\n",
    "\n",
    "- Note that one way to choose the last axis in a tensor is to use negative indexing (axis=-1).\n",
    "\n",
    "- In step 4, when summing over training examples, the result will be a single scalar value.\n",
    "\n",
    "- For `tf.reduce_sum` to sum across all axes, keep the default value axis=None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29fad7814c380400d588375341b0dfc3",
     "grade": false,
     "grade_id": "cell-f05732f7068382cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: triplet_loss\n",
    "\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    # YOUR CODE STARTS HERE (â 4 lines)\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.maximum(tf.add(tf.subtract(pos_dist,neg_dist),alpha),0)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(basic_loss)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "902d2a22882a6bbd15dc99e1bb5e6d09",
     "grade": true,
     "grade_id": "cell-440ff81e6bcda96a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = tf.Tensor(527.2598, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "y_true = (None, None, None) # It is not used\n",
    "y_pred = (tf.keras.backend.random_normal([3, 128], mean=6, stddev=0.1, seed = 1),\n",
    "          tf.keras.backend.random_normal([3, 128], mean=1, stddev=1, seed = 1),\n",
    "          tf.keras.backend.random_normal([3, 128], mean=3, stddev=4, seed = 1))\n",
    "loss = triplet_loss(y_true, y_pred)\n",
    "\n",
    "# assert type(loss) == tf.python.framework.ops.EagerTensor, \"Use tensorflow functions\"\n",
    "print(\"loss = \" + str(loss))\n",
    "\n",
    "y_pred_perfect = ([1., 1.], [1., 1.], [1., 1.,])\n",
    "loss = triplet_loss(y_true, y_pred_perfect, 5)\n",
    "assert loss == 5, \"Wrong value. Did you add the alpha to basic_loss?\"\n",
    "y_pred_perfect = ([1., 1.],[1., 1.], [0., 0.,])\n",
    "loss = triplet_loss(y_true, y_pred_perfect, 3)\n",
    "assert loss == 1., \"Wrong value. Check that pos_dist = 0 and neg_dist = 2 in this example\"\n",
    "y_pred_perfect = ([1., 1.],[0., 0.], [1., 1.,])\n",
    "loss = triplet_loss(y_true, y_pred_perfect, 0)\n",
    "assert loss == 2., \"Wrong value. Check that pos_dist = 2 and neg_dist = 0 in this example\"\n",
    "y_pred_perfect = ([0., 0.],[0., 0.], [0., 0.,])\n",
    "loss = triplet_loss(y_true, y_pred_perfect, -2)\n",
    "assert loss == 0, \"Wrong value. Are you taking the maximum between basic_loss and 0?\"\n",
    "y_pred_perfect = ([[1., 0.], [1., 0.]],[[1., 0.], [1., 0.]], [[0., 1.], [0., 1.]])\n",
    "loss = triplet_loss(y_true, y_pred_perfect, 3)\n",
    "assert loss == 2., \"Wrong value. Are you applying tf.reduce_sum to get the loss?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>loss</b>\n",
    "        </td>\n",
    "        <td>\n",
    "           527.2598\n",
    "        </td>\n",
    "    </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Loading the Pre-trained Model\n",
    "\n",
    "FaceNet is trained by minimizing the triplet loss. But since training requires a lot of data and a lot of computation, you won't train it from scratch here. Instead, you'll load a previously trained model in the following cell; which might take a couple of minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c3d572d031c34290a2d758eebabd003",
     "grade": false,
     "grade_id": "cell-953bcab8e9bbba10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "FRmodel = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some examples of distances between the encodings between three individuals:\n",
    "\n",
    "<img src=\"images/distance_matrix.png\" style=\"width:380px;height:200px;\"><br>\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 4:</b></u> <br>  <font color='purple'> Example of distance outputs between three individuals' encodings</center></caption>\n",
    "\n",
    "Now use this model to perform face verification and face recognition!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Applying the Model\n",
    "\n",
    "You're building a system for an office building where the building manager would like to offer facial recognition to allow the employees to enter the building.\n",
    "\n",
    "You'd like to build a face verification system that gives access to a list of people. To be admitted, each person has to swipe an identification card at the entrance. The face recognition system then verifies that they are who they claim to be.\n",
    "\n",
    "<a name='5-1'></a>\n",
    "### 5.1 - Face Verification\n",
    "\n",
    "Now you'll build a database containing one encoding vector for each person who is allowed to enter the office. To generate the encoding, you'll use `img_to_encoding(image_path, model)`, which runs the forward propagation of the model on the specified image.\n",
    "\n",
    "Run the following code to build the database (represented as a Python dictionary). This database maps each person's name to a 128-dimensional encoding of their face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.backend.set_image_data_format('channels_last')\n",
    "def img_to_encoding(image_path, model):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(160, 160))\n",
    "    img = np.around(np.array(img) / 255.0, decimals=12)\n",
    "    x_train = np.expand_dims(img, axis=0)\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding / np.linalg.norm(embedding, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"danielle\"] = img_to_encoding(\"images/danielle.png\", FRmodel)\n",
    "database[\"younes\"] = img_to_encoding(\"images/younes.jpg\", FRmodel)\n",
    "database[\"tian\"] = img_to_encoding(\"images/tian.jpg\", FRmodel)\n",
    "database[\"andrew\"] = img_to_encoding(\"images/andrew.jpg\", FRmodel)\n",
    "database[\"kian\"] = img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
    "database[\"dan\"] = img_to_encoding(\"images/dan.jpg\", FRmodel)\n",
    "database[\"sebastiano\"] = img_to_encoding(\"images/sebastiano.jpg\", FRmodel)\n",
    "database[\"bertrand\"] = img_to_encoding(\"images/bertrand.jpg\", FRmodel)\n",
    "database[\"kevin\"] = img_to_encoding(\"images/kevin.jpg\", FRmodel)\n",
    "database[\"felix\"] = img_to_encoding(\"images/felix.jpg\", FRmodel)\n",
    "database[\"benoit\"] = img_to_encoding(\"images/benoit.jpg\", FRmodel)\n",
    "database[\"arnaud\"] = img_to_encoding(\"images/arnaud.jpg\", FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the images of Danielle and Kian: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "danielle = tf.keras.preprocessing.image.load_img(\"images/danielle.png\", target_size=(160, 160))\n",
    "kian = tf.keras.preprocessing.image.load_img(\"images/kian.jpg\", target_size=(160, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.around(np.array(kian) / 255.0, decimals=12).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=160x160>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 160, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benoit = tf.keras.preprocessing.image.load_img(\"images/benoit.jpg\", target_size=(160, 160))\n",
    "np.around(np.array(benoit) / 255.0, decimals=12).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=160x160>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benoit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 160, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(np.array(danielle) / 255.0, decimals=12).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=160x160>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "danielle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when someone shows up at your front door and swipes their ID card (thus giving you their name), you can look up their encoding in the database, and use it to check if the person standing at the front door matches the name on the ID.\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Exercise 2 - verify\n",
    "\n",
    "Implement the `verify()` function, which checks if the front-door camera picture (`image_path`) is actually the person called \"identity\". You will have to go through the following steps:\n",
    "\n",
    "- Compute the encoding of the image from `image_path`.\n",
    "- Compute the distance between this encoding and the encoding of the identity image stored in the database.\n",
    "- Open the door if the distance is less than 0.7, else do not open it.\n",
    "\n",
    "As presented above, you should use the L2 distance `np.linalg.norm`.\n",
    "\n",
    "**Note**: In this implementation, compare the L2 distance, not the square of the L2 distance, to the threshold 0.7.\n",
    "\n",
    "*Hints*:\n",
    "\n",
    "- `identity` is a string that is also a key in the database dictionary.\n",
    "- `img_to_encoding` has two parameters: the image_path and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5181bf2eefe1a15151de731e6baeb4b9",
     "grade": false,
     "grade_id": "cell-ba2f317e79e15a2f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: verify\n",
    "\n",
    "def verify(image_path, identity, database, model):\n",
    "    \"\"\"\n",
    "    Function that verifies if the person on the \"image_path\" image is \"identity\".\n",
    "    \n",
    "    Arguments:\n",
    "        image_path -- path to an image\n",
    "        identity -- string, name of the person you'd like to verify the identity. Has to be an employee who works in the office.\n",
    "        database -- python dictionary mapping names of allowed people's names (strings) to their encodings (vectors).\n",
    "        model -- your Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "        dist -- distance between the image_path and the image of \"identity\" in the database.\n",
    "        door_open -- True, if the door should open. False otherwise.\n",
    "    \"\"\"\n",
    "        \n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    #Step 1: Compute the encoding for the image. Use img_to_encoding() see example above. (â 1 line)\n",
    "    encoding = img_to_encoding(image_path,model)\n",
    "    # Step 2: Compute distance with identity's image (â 1 line)\n",
    "    dist = np.linalg.norm(encoding - database[identity])\n",
    "    # Step 3: Open the door if dist < 0.7, else don't open (â 3 lines)\n",
    "    if dist < 0.7:\n",
    "        print(\"It's \" + str(identity) + \", welcome in!\")\n",
    "        door_open = True\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "        door_open = False\n",
    "\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "        \n",
    "    return dist, door_open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Younes is trying to enter the office and the camera takes a picture of him (\"images/camera_0.jpg\"). Let's run your verification algorithm on this picture:\n",
    "\n",
    "<img src=\"images/camera_0.jpg\" style=\"width:100px;height:100px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc561d44a84cd1bc2309e10140b370df",
     "grade": true,
     "grade_id": "cell-014d077254ad7d52",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's bertrand, welcome in!\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_94735/4234450063.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/camera_1.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bertrand\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.54364836\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/camera_3.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bertrand\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.38616243\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/camera_1.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"younes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.3963861\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/camera_3.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"younes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.3872949\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/camera_0.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"younes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(np.allclose(verify(\"images/camera_1.jpg\", \"bertrand\", database, FRmodel), (0.54364836, True)))\n",
    "assert(np.allclose(verify(\"images/camera_3.jpg\", \"bertrand\", database, FRmodel), (0.38616243, True)))\n",
    "assert(np.allclose(verify(\"images/camera_1.jpg\", \"younes\", database, FRmodel), (1.3963861, False)))\n",
    "assert(np.allclose(verify(\"images/camera_3.jpg\", \"younes\", database, FRmodel), (1.3872949, False)))\n",
    "verify(\"images/camera_0.jpg\", \"younes\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>It's Younes, welcome in!</b>\n",
    "        </td>\n",
    "        <td>\n",
    "           (0.5992946, True)\n",
    "        </td>\n",
    "    </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benoit, who does not work in the office, stole Kian's ID card and tried to enter the office. Naughty Benoit! The camera took a picture of Benoit (\"images/camera_2.jpg). \n",
    "\n",
    "<img src=\"images/camera_2.jpg\" style=\"width:100px;height:100px;\">\n",
    "\n",
    "Run the verification algorithm to check if Benoit can enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's not kian, please go away\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0130049, False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"images/camera_2.jpg\", \"kian\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>It's not Kian, please go away</b>\n",
    "        </td>\n",
    "        <td>\n",
    "           (1.0259346, False)\n",
    "        </td>\n",
    "    </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the verification algorithm to check if Andrew can enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's andrew, welcome in!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"images/andrew.jpg\", \"andrew\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5-2'></a>\n",
    "### 5.2 - Face Recognition\n",
    "\n",
    "Your face verification system is mostly working. But since Kian got his ID card stolen, when he came back to the office the next day he couldn't get in!\n",
    "\n",
    "To solve this, you'd like to change your face verification system to a face recognition system. This way, no one has to carry an ID card anymore. An authorized person can just walk up to the building, and the door will unlock for them!\n",
    "\n",
    "You'll implement a face recognition system that takes as input an image, and figures out if it is one of the authorized persons (and if so, who). Unlike the previous face verification system, you will no longer get a person's name as one of the inputs.\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Exercise 3 - who_is_it\n",
    "\n",
    "Implement `who_is_it()` with the following steps:\n",
    "\n",
    "- Compute the target encoding of the image from `image_path`\n",
    "- Find the encoding from the database that has smallest distance with the target encoding.\n",
    "- Initialize the `min_dist` variable to a large enough number (100). This helps you keep track of the closest encoding to the input's encoding.\n",
    "- Loop over the database dictionary's names and encodings. To loop use for (name, db_enc) in `database.items()`.\n",
    "- Compute the L2 distance between the target \"encoding\" and the current \"encoding\" from the database. If this distance is less than the min_dist, then set min_dist to dist, and identity to name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53575b9e1fab82ed7e0c41f86caf0d49",
     "grade": false,
     "grade_id": "cell-a04ff2b5fd1186f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: who_is_it\n",
    "\n",
    "def who_is_it(image_path, database, model):\n",
    "    \"\"\"\n",
    "    Implements face recognition for the office by finding who is the person on the image_path image.\n",
    "    \n",
    "    Arguments:\n",
    "        image_path -- path to an image\n",
    "        database -- database containing image encodings along with the name of the person on the image\n",
    "        model -- your Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "        min_dist -- the minimum distance between image_path encoding and the encodings from the database\n",
    "        identity -- string, the name prediction for the person on image_path\n",
    "    \"\"\"\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    ## Step 1: Compute the target \"encoding\" for the image. Use img_to_encoding() see example above. ## (â 1 line)\n",
    "    encoding = img_to_encoding(image_path,model)\n",
    "    \n",
    "    ## Step 2: Find the closest encoding ##\n",
    "    # Initialize \"min_dist\" to a large value, say 100 (â1 line)\n",
    "    min_dist = 100\n",
    "    \n",
    "    #Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "        \n",
    "        # Compute L2 distance between the target \"encoding\" and the current db_enc from the database. (â 1 line)\n",
    "        dist = np.linalg.norm(encoding - db_enc)\n",
    "\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (â 3 lines)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    if min_dist > 0.7:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Younes is at the front door and the camera takes a picture of him (\"images/camera_0.jpg\"). Let's see if your `who_it_is()` algorithm identifies Younes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47d418fef13b11ccc87e4912484ca8d4",
     "grade": true,
     "grade_id": "cell-9c88c8ab87677503",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's younes, the distance is 0.60197926\n",
      "it's younes, the distance is 0.60197926\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_94735/260244612.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Test 2 with Younes pictures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwho_is_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/camera_0.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5992946\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'younes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test 1 with Younes pictures \n",
    "who_is_it(\"images/camera_0.jpg\", database, FRmodel)\n",
    "\n",
    "# Test 2 with Younes pictures \n",
    "test1 = who_is_it(\"images/camera_0.jpg\", database, FRmodel)\n",
    "assert np.isclose(test1[0], 0.5992946)\n",
    "assert test1[1] == 'younes'\n",
    "\n",
    "# Test 3 with Younes pictures \n",
    "test2 = who_is_it(\"images/younes.jpg\", database, FRmodel)\n",
    "assert np.isclose(test2[0], 0.0)\n",
    "assert test2[1] == 'younes'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>it's Younes, the distance is 0.5992946</b>\n",
    "        </td>\n",
    "        <td>\n",
    "           (0.5992946, 'younes')\n",
    "        </td>\n",
    "    </tr>\n",
    "    </table>\n",
    "\n",
    "You can change \"camera_0.jpg\" (picture of Younes) to \"camera_1.jpg\" (picture of Bertrand) and see the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations**! \n",
    "You've completed this assignment, and your face recognition system is working well! It not only lets in authorized persons, but now people don't need to carry an ID card around anymore!\n",
    "\n",
    "You've now seen how a state-of-the-art face recognition system works, and can describe the difference between face recognition and face verification. Here's a quick recap of what you've accomplished: \n",
    "\n",
    "- Posed face recognition as a binary classification problem\n",
    "- Implemented one-shot learning for a face recognition problem\n",
    "- Applied the triplet loss function to learn a network's parameters in the context of face recognition\n",
    "- Mapped face images into 128-dimensional encodings using a pretrained model\n",
    "- Performed face verification and face recognition with these encodings\n",
    "\n",
    "Great work! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**What you should remember**:\n",
    "\n",
    "- Face verification solves an easier 1:1 matching problem; face recognition addresses a harder 1:K matching problem.\n",
    "    \n",
    "- Triplet loss is an effective loss function for training a neural network to learn an encoding of a face image.\n",
    "    \n",
    "- The same encoding can be used for verification and recognition. Measuring distances between two images' encodings allows you to determine whether they are pictures of the same person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ways to improve your facial recognition model**:\n",
    "\n",
    "Although you won't implement these here, here are some ways to further improve the algorithm:\n",
    "\n",
    "- Put more images of each person (under different lighting conditions, taken on different days, etc.) into the database. Then, given a new image, compare the new face to multiple pictures of the person. This would increase accuracy.\n",
    "\n",
    "- Crop the images to contain just the face, and less of the \"border\" region around the face. This preprocessing removes some of the irrelevant pixels around the face, and also makes the algorithm more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - References\n",
    "1. Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf)\n",
    "\n",
    "2. Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, Lior Wolf (2014). [DeepFace: Closing the gap to human-level performance in face verification](https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf)\n",
    "\n",
    "3. This implementation also took a lot of inspiration from the official FaceNet github repository: https://github.com/davidsandberg/facenet\n",
    "\n",
    "4. Further inspiration was found here: https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/\n",
    "\n",
    "5. And here: https://github.com/nyoki-mtl/keras-facenet/blob/master/notebook/tf_to_keras.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5030792b3492f6b12d94f1f48beca3d8e59ec05fd59d0aaaa48e684281ed297"
  },
  "kernelspec": {
   "display_name": "Python 3.7.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
